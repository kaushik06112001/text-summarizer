{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2gs80st8Alm",
        "outputId": "377be74e-c12e-409b-cd4a-d27f719e3eed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\hiten\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\hiten\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "dDo2a2lW8chZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "def text_summarizer(text, num_sentences=3):\n",
        "    # Tokenize text into sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "    \n",
        "    # Tokenize words and remove stopwords\n",
        "    words = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word.lower() not in stop_words and word.isalnum()]\n",
        "    \n",
        "    # Calculate word frequency\n",
        "    freq_dist = FreqDist(words)\n",
        "\n",
        "    # Score sentences based on word frequency\n",
        "    sentence_scores = {}\n",
        "    for sentence in sentences: #to iterate through all the sentences\n",
        "        for word in word_tokenize(sentence.lower()): #to iterate through all the words in a sentence\n",
        "            if word in freq_dist: #to exclude the stopwords and only iterate through words that are in the freq distribution table\n",
        "                if sentence not in sentence_scores:             #if the sentence is not in the sentence_score dictionary put the freq of the word from the freq_dist table as value\n",
        "                    sentence_scores[sentence] = freq_dist[word] #against the sentence\n",
        "                else:                                           #else add the freq of the word t0 the sentence_score\n",
        "                    sentence_scores[sentence] += freq_dist[word]\n",
        "\n",
        "    # sort the sentences in descending order and select the required no. of sentences from the top\n",
        "    top_sentences = sorted(sentence_scores, key=sentence_scores.get, reverse=True)[:num_sentences] #sort the sentences in descending order and select the required no. of sentences\n",
        "    print(sentence_scores)\n",
        "    # Generate summary\n",
        "    summary = ' '.join(top_sentences)\n",
        "    return summary\n",
        "\n",
        "# text=input(\"Enter: \")\n",
        "# print(text_summarizer(text))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {},
      "outputs": [],
      "source": [
        "#NEWS API IMPORT__________________:\n",
        "\n",
        "\n",
        "#extraction of html content form website\n",
        "def extract_content_from_url(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        body = soup.find_all(\"p\",class_=\"ssrcss-1q0x1qg-Paragraph e1jhz7w10\")#main showinf\n",
        "        content=\"\"\n",
        "        for para in body:\n",
        "            # content=para.get_text(separator=\"\\n\").strip()  #remove extra spaces at the beginning and end of each paragraph  \n",
        "            content += para.get_text().strip() + \"\\n\"  # Concatenate paragraphs with a newline separator\n",
        "            \n",
        "        return content\n",
        "        # main_contents = []\n",
        "        \n",
        "        # for section in sections:\n",
        "        #     p_elements = section.find_all(\"p\", class_=\"sc-e1853509-0 bmLndb\")\n",
        "        #     main_contents.extend(p_elements)# Adjust the class name based on the structure of the website\n",
        "        #     print(\"p elements: \",p_elements)\n",
        "        #     print(\"main contents:\", main_contents)\n",
        "        # contents=[]\n",
        "        # for main_content in main_contents:\n",
        "        #     # Extract the text from each main content element\n",
        "        #     content = main_content.get_text(separator=\"\\n\")\n",
        "        #     contents.append(content)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred while extracting content: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the News API endpoint and your API key\n",
        "NEWS_API_ENDPOINT = \"https://newsapi.org/v2/everything\"\n",
        "API_KEY = \"14fcdfa8144447cd9fe65ca72451d9cc\"\n",
        "\n",
        "# Function to fetch news articles and summarize them\n",
        "def fetch_and_summarize_news(query, num_sentences=3):\n",
        "    params = {\n",
        "        \"q\": query,\n",
        "        \"apiKey\": API_KEY,\n",
        "        \"pageSize\": 4,\n",
        "        \"language\": 'en',\n",
        "        \"domains\": 'bbc.co.uk'  # Filter results by domain\n",
        "    }\n",
        "    response =  requests.get(NEWS_API_ENDPOINT, params=params)\n",
        "    articles = response.json()[\"articles\"]\n",
        "    \n",
        "    titles=[]\n",
        "    urls=[]\n",
        "    contents=[]\n",
        "    summaries=[]\n",
        "    for article in articles:\n",
        "        text = extract_content_from_url(article[\"url\"])\n",
        "        if text:\n",
        "            titles.append(article[\"title\"])\n",
        "            urls.append(article[\"url\"])\n",
        "            contents.append(text)  # Extract content from URL\n",
        "            summary = text_summarizer(text, num_sentences)\n",
        "            summaries.append(summary)\n",
        "    return titles,urls,contents,summaries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Example usage\n",
        "query = input(\"Enter a topic to search for news articles: \")\n",
        "num_sentences = int(input(\"Enter the number of sentences for each summary: \"))\n",
        "titles,urls,contents,summaries= fetch_and_summarize_news(query, num_sentences)\n",
        "for i in range(len(titles)):\n",
        "    print(f\"\"\"\\nTitle ->{titles[i]}:\\n\n",
        "            \\nURL ->{urls[i]}\\n\n",
        "            \\nContent ->{contents[i]}\\n\n",
        "            \\nSummaries ->{summaries[i]}\\n\\n\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#>>>>>>>>> text out of main class <<<<<<<<\n",
        "def get_txt(url: str) -> list:\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    body = soup.find(\"main\").text#main showinf\n",
        "    return body\n",
        "    # para = []\n",
        "    # sections = body.find_all('section')  # Find all <section> elements within the <main>\n",
        "    # print(len(sections))\n",
        "    # print(sections)\n",
        "    # for section in sections:  # Iterate over each <section> element\n",
        "    #     para.extend(section.find('p'))  # Find all <p> elements within the <section> and append to para list\n",
        "    # return para\n",
        "\n",
        "url = 'https://www.bbc.co.uk/news/world-asia-india-68758637'\n",
        "print(get_txt(url))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#>>>>>>>> BETTER TEXT EXTRACTION FROM WEBSITE<<<<<<<<<<\n",
        "def get_txt(url: str) :\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    body = soup.find_all(\"p\",class_=\"ssrcss-1q0x1qg-Paragraph e1jhz7w10\")#main showinf\n",
        "    content=\"\"\n",
        "    for para in body:\n",
        "        # content=para.get_text(separator=\"\\n\").strip()  #remove extra spaces at the beginning and end of each paragraph  \n",
        "         content += para.get_text().strip() + \"\\n\"  # Concatenate paragraphs with a newline separator\n",
        "          \n",
        "    return content\n",
        "url = 'https://www.bbc.co.uk/news/world-asia-india-68758637'\n",
        "print(get_txt(url))\n",
        "# for section in sections:\n",
        "        #     p_elements = section.find_all(\"p\", class_=\"sc-e1853509-0 bmLndb\")\n",
        "        #     main_contents.extend(p_elements)# Adjust the class name based on the structure of the website\n",
        "        #     print(\"p elements: \",p_elements)\n",
        "        #     print(\"main contents:\", main_contents)\n",
        "        # contents=[]\n",
        "        # for main_content in main_contents:\n",
        "        #     # Extract the text from each main content element\n",
        "        #     content = main_content.get_text(separator=\"\\n\")\n",
        "        #     contents.append(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[WARNING] [Config      ] Older configuration version detected (0 instead of 27)\n",
            "[WARNING] [Config      ] Upgrading configuration in progress.\n",
            "[DEBUG  ] [Config      ] Upgrading from 0 to 1\n",
            "[INFO   ] [Logger      ] Record log in C:\\Users\\hiten\\.kivy\\logs\\kivy_24-04-18_0.txt\n",
            "[ERROR  ] [Core        ] option --ip not recognized\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kivy Usage: ipykernel_launcher.py [KIVY OPTION...] [-- PROGRAM OPTIONS]::\n",
            "\n",
            "            Options placed after a '-- ' separator, will not be touched by kivy,\n",
            "            and instead passed to your program.\n",
            "\n",
            "            Set KIVY_NO_ARGS=1 in your environment or before you import Kivy to\n",
            "            disable Kivy's argument parser.\n",
            "\n",
            "        -h, --help\n",
            "            Prints this help message.\n",
            "        -d, --debug\n",
            "            Shows debug log.\n",
            "        -a, --auto-fullscreen\n",
            "            Force 'auto' fullscreen mode (no resolution change).\n",
            "            Uses your display's resolution. This is most likely what you want.\n",
            "        -c, --config section:key[:value]\n",
            "            Set a custom [section] key=value in the configuration object.\n",
            "        -f, --fullscreen\n",
            "            Force running in fullscreen mode.\n",
            "        -k, --fake-fullscreen\n",
            "            Force 'fake' fullscreen mode (no window border/decoration).\n",
            "            Uses the resolution specified by width and height in your config.\n",
            "        -w, --windowed\n",
            "            Force running in a window.\n",
            "        -p, --provider id:provider[,options]\n",
            "            Add an input provider (eg: ccvtable1:tuio,192.168.0.1:3333).\n",
            "        -m mod, --module=mod\n",
            "            Activate a module (use \"list\" to get a list of available modules).\n",
            "        -r, --rotation\n",
            "            Rotate the window's contents (0, 90, 180, 270).\n",
            "        -s, --save\n",
            "            Save current Kivy configuration.\n",
            "        --size=640x480\n",
            "            Size of window geometry.\n",
            "        --dpi=96\n",
            "            Manually overload the Window DPI (for testing only.)\n",
            "    \n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'tuple' object has no attribute 'tb_frame'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mGetoptError\u001b[0m                               Traceback (most recent call last)",
            "File \u001b[1;32md:\\vs code\\text-summarizer\\myproject\\lib\\site-packages\\kivy\\__init__.py:392\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 392\u001b[0m     opts, args \u001b[39m=\u001b[39m getopt(sys_argv[\u001b[39m1\u001b[39;49m:], \u001b[39m'\u001b[39;49m\u001b[39mhp:fkawFem:sr:dc:\u001b[39;49m\u001b[39m'\u001b[39;49m, [\n\u001b[0;32m    393\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mhelp\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mfullscreen\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mwindowed\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mfps\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mevent\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m    394\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mmodule=\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39msave\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mfake-fullscreen\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mauto-fullscreen\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m    395\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mmultiprocessing-fork\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mdisplay=\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39msize=\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrotate=\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m    396\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mconfig=\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mdebug\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mdpi=\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m    398\u001b[0m \u001b[39mexcept\u001b[39;00m GetoptError \u001b[39mas\u001b[39;00m err:\n",
            "File \u001b[1;32mC:\\Python310\\lib\\getopt.py:93\u001b[0m, in \u001b[0;36mgetopt\u001b[1;34m(args, shortopts, longopts)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m args[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39m--\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m---> 93\u001b[0m     opts, args \u001b[39m=\u001b[39m do_longs(opts, args[\u001b[39m0\u001b[39;49m][\u001b[39m2\u001b[39;49m:], longopts, args[\u001b[39m1\u001b[39;49m:])\n\u001b[0;32m     94\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[1;32mC:\\Python310\\lib\\getopt.py:157\u001b[0m, in \u001b[0;36mdo_longs\u001b[1;34m(opts, opt, longopts, args)\u001b[0m\n\u001b[0;32m    155\u001b[0m     opt, optarg \u001b[39m=\u001b[39m opt[:i], opt[i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m:]\n\u001b[1;32m--> 157\u001b[0m has_arg, opt \u001b[39m=\u001b[39m long_has_args(opt, longopts)\n\u001b[0;32m    158\u001b[0m \u001b[39mif\u001b[39;00m has_arg:\n",
            "File \u001b[1;32mC:\\Python310\\lib\\getopt.py:174\u001b[0m, in \u001b[0;36mlong_has_args\u001b[1;34m(opt, longopts)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m possibilities:\n\u001b[1;32m--> 174\u001b[0m     \u001b[39mraise\u001b[39;00m GetoptError(_(\u001b[39m'\u001b[39m\u001b[39moption --\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m not recognized\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m%\u001b[39m opt, opt)\n\u001b[0;32m    175\u001b[0m \u001b[39m# Is there an exact match?\u001b[39;00m\n",
            "\u001b[1;31mGetoptError\u001b[0m: option --ip not recognized",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "Cell \u001b[1;32mIn[180], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mkivy\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkivy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapp\u001b[39;00m \u001b[39mimport\u001b[39;00m App\n",
            "File \u001b[1;32md:\\vs code\\text-summarizer\\myproject\\lib\\site-packages\\kivy\\__init__.py:401\u001b[0m\n\u001b[0;32m    400\u001b[0m     kivy_usage()\n\u001b[1;32m--> 401\u001b[0m     sys\u001b[39m.\u001b[39;49mexit(\u001b[39m2\u001b[39;49m)\n\u001b[0;32m    403\u001b[0m mp_fork \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "\u001b[1;31mSystemExit\u001b[0m: 2",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "File \u001b[1;32md:\\vs code\\text-summarizer\\myproject\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2145\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2142\u001b[0m \u001b[39mif\u001b[39;00m exception_only:\n\u001b[0;32m   2143\u001b[0m     stb \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mAn exception has occurred, use \u001b[39m\u001b[39m%\u001b[39m\u001b[39mtb to see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   2144\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mthe full traceback.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m]\n\u001b[1;32m-> 2145\u001b[0m     stb\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mInteractiveTB\u001b[39m.\u001b[39;49mget_exception_only(etype,\n\u001b[0;32m   2146\u001b[0m                                                      value))\n\u001b[0;32m   2147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2149\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcontains_exceptiongroup\u001b[39m(val):\n",
            "File \u001b[1;32md:\\vs code\\text-summarizer\\myproject\\lib\\site-packages\\IPython\\core\\ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_exception_only\u001b[39m(\u001b[39mself\u001b[39m, etype, value):\n\u001b[0;32m    703\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \n\u001b[0;32m    705\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[39m    value : exception value\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 710\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39;49mstructured_traceback(\u001b[39mself\u001b[39;49m, etype, value)\n",
            "File \u001b[1;32md:\\vs code\\text-summarizer\\myproject\\lib\\site-packages\\IPython\\core\\ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    565\u001b[0m     chained_exc_ids\u001b[39m.\u001b[39madd(\u001b[39mid\u001b[39m(exception[\u001b[39m1\u001b[39m]))\n\u001b[0;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    567\u001b[0m     out_list \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 568\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m    569\u001b[0m             etype,\n\u001b[0;32m    570\u001b[0m             evalue,\n\u001b[0;32m    571\u001b[0m             (etb, chained_exc_ids),  \u001b[39m# type: ignore\u001b[39;49;00m\n\u001b[0;32m    572\u001b[0m             chained_exceptions_tb_offset,\n\u001b[0;32m    573\u001b[0m             context,\n\u001b[0;32m    574\u001b[0m         )\n\u001b[0;32m    575\u001b[0m         \u001b[39m+\u001b[39m chained_exception_message\n\u001b[0;32m    576\u001b[0m         \u001b[39m+\u001b[39m out_list)\n\u001b[0;32m    578\u001b[0m \u001b[39mreturn\u001b[39;00m out_list\n",
            "File \u001b[1;32md:\\vs code\\text-summarizer\\myproject\\lib\\site-packages\\IPython\\core\\ultratb.py:1454\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1452\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1453\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtb \u001b[39m=\u001b[39m etb\n\u001b[1;32m-> 1454\u001b[0m \u001b[39mreturn\u001b[39;00m FormattedTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m   1455\u001b[0m     \u001b[39mself\u001b[39;49m, etype, evalue, etb, tb_offset, number_of_lines_of_context\n\u001b[0;32m   1456\u001b[0m )\n",
            "File \u001b[1;32md:\\vs code\\text-summarizer\\myproject\\lib\\site-packages\\IPython\\core\\ultratb.py:1345\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1342\u001b[0m mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\n\u001b[0;32m   1343\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose_modes:\n\u001b[0;32m   1344\u001b[0m     \u001b[39m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1345\u001b[0m     \u001b[39mreturn\u001b[39;00m VerboseTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m   1346\u001b[0m         \u001b[39mself\u001b[39;49m, etype, value, tb, tb_offset, number_of_lines_of_context\n\u001b[0;32m   1347\u001b[0m     )\n\u001b[0;32m   1348\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMinimal\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m   1349\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39mget_exception_only(\u001b[39mself\u001b[39m, etype, value)\n",
            "File \u001b[1;32md:\\vs code\\text-summarizer\\myproject\\lib\\site-packages\\IPython\\core\\ultratb.py:1192\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1183\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstructured_traceback\u001b[39m(\n\u001b[0;32m   1184\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1185\u001b[0m     etype: \u001b[39mtype\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     number_of_lines_of_context: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m,\n\u001b[0;32m   1190\u001b[0m ):\n\u001b[0;32m   1191\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1192\u001b[0m     formatted_exception \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m   1193\u001b[0m                                                            tb_offset)\n\u001b[0;32m   1195\u001b[0m     colors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mColors  \u001b[39m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m     colorsnormal \u001b[39m=\u001b[39m colors\u001b[39m.\u001b[39mNormal  \u001b[39m# used a lot\u001b[39;00m\n",
            "File \u001b[1;32md:\\vs code\\text-summarizer\\myproject\\lib\\site-packages\\IPython\\core\\ultratb.py:1082\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(tb_offset, \u001b[39mint\u001b[39m)\n\u001b[0;32m   1080\u001b[0m head \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_header(\u001b[39mstr\u001b[39m(etype), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlong_header)\n\u001b[0;32m   1081\u001b[0m records \u001b[39m=\u001b[39m (\n\u001b[1;32m-> 1082\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_records(etb, number_of_lines_of_context, tb_offset) \u001b[39mif\u001b[39;00m etb \u001b[39melse\u001b[39;00m []\n\u001b[0;32m   1083\u001b[0m )\n\u001b[0;32m   1085\u001b[0m frames \u001b[39m=\u001b[39m []\n\u001b[0;32m   1086\u001b[0m skipped \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
            "File \u001b[1;32md:\\vs code\\text-summarizer\\myproject\\lib\\site-packages\\IPython\\core\\ultratb.py:1150\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[39mwhile\u001b[39;00m cf \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1150\u001b[0m         mod \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39mgetmodule(cf\u001b[39m.\u001b[39;49mtb_frame)\n\u001b[0;32m   1151\u001b[0m         \u001b[39mif\u001b[39;00m mod \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1152\u001b[0m             mod_name \u001b[39m=\u001b[39m mod\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
          ]
        }
      ],
      "source": [
        "import kivy\n",
        "from kivy.app import App\n",
        "from kivy.uix.label import Label\n",
        "from kivy.uix.scrollview import ScrollView\n",
        "from kivy.uix.gridlayout import GridLayout\n",
        "from kivy.uix.button import Button\n",
        "from kivy.uix.textinput import TextInput\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "class TextScrapingApp(App):\n",
        "    def build(self):\n",
        "        self.title = 'Text Scraping App'\n",
        "        \n",
        "        layout = GridLayout(cols=1, spacing=10, size_hint_y=None)\n",
        "        layout.bind(minimum_height=layout.setter('height'))\n",
        "        \n",
        "        url_input = TextInput(hint_text='Enter URL', multiline=False)\n",
        "        layout.add_widget(url_input)\n",
        "        \n",
        "        scroll_view = ScrollView()\n",
        "        self.content_label = Label(text='', valign='top', size_hint_y=None)\n",
        "        scroll_view.add_widget(self.content_label)\n",
        "        layout.add_widget(scroll_view)\n",
        "        \n",
        "        fetch_button = Button(text='Fetch Content', size_hint_y=None, height=40)\n",
        "        fetch_button.bind(on_press=lambda instance: self.fetch_content(url_input.text))\n",
        "        layout.add_widget(fetch_button)\n",
        "        \n",
        "        return layout\n",
        "    \n",
        "    def fetch_content(self, url):\n",
        "        try:\n",
        "            content = self.get_txt(url)\n",
        "            self.content_label.text = content\n",
        "        except Exception as e:\n",
        "            self.content_label.text = f'Error: {str(e)}'\n",
        "    \n",
        "    def get_txt(self, url):\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        body = soup.find_all(\"p\", class_=\"ssrcss-1q0x1qg-Paragraph e1jhz7w10\")  # main showinf\n",
        "        content = \"\"\n",
        "        for para in body:\n",
        "            content += para.get_text().strip() + \"\\n\"  # Concatenate paragraphs with a newline separator\n",
        "        return content\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    TextScrapingApp().run()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrJRhm4i8hf3",
        "outputId": "565c82bb-ac99-422c-e782-49e02bbc236f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In the interview, a teary Ms Higgins had detailed how she had woken up on a couch in a minister's office to find a colleague on top of her in 2019. Political staffer Bruce Lehrmann has always denied sex with Brittany Higgins and sued Network 10 for defamation over a 2021 TV interview with her. Ruling that Mr Lehrmann's defamation case be thrown out, Federal Court Justice Michael Lee said the 28-year-old had been \"hellbent\" on having sex with Ms Higgins and was \"indifferent\" to whether she wanted to as well.\n"
          ]
        }
      ],
      "source": [
        "# >>>>>>>>>>>>> FIRST INTERFACE <<<<<<<<<<<<\n",
        "# Example usage\n",
        "text=input(\"\\nEnter the text u want to summarize:\\n\")\n",
        "n=int(input(\"\\nEnter the no. of sentences: \"))\n",
        "summary = text_summarizer(text)\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#>>>>>>>>>> FOR ENDPOINT EVERYTHING <<<<<<<<<<<\n",
        "\n",
        "\n",
        "\n",
        "#NEWS API IMPORT__________________:\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "#extraction of html content form website\n",
        "def extract_content_from_url(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        # Find the element containing the main content of the article\n",
        "        main_content = soup.find(\"div\", class_=\"article-body\")  # Adjust the class name based on the structure of the website\n",
        "        if main_content:\n",
        "            # Extract the text from the main content element\n",
        "            content = main_content.get_text(separator=\"\\n\")\n",
        "            return content\n",
        "        else:\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred while extracting content: {e}\")\n",
        "        return None\n",
        "    \n",
        "# Define the News API endpoint and your API key\n",
        "NEWS_API_ENDPOINT = \"https://newsapi.org/v2/everything\"\n",
        "API_KEY = \"14fcdfa8144447cd9fe65ca72451d9cc\"\n",
        "\n",
        "# Function to fetch news articles and summarize them\n",
        "def fetch_and_summarize_news(query, num_sentences=3):\n",
        "    params = {\n",
        "        \"q\": query,\n",
        "        \"apiKey\": API_KEY,\n",
        "        \"pageSize\": 3\n",
        "    }\n",
        "    response = requests.get(NEWS_API_ENDPOINT, params=params)\n",
        "    articles = response.json()[\"articles\"]\n",
        "    \n",
        "    titles=[]\n",
        "    summaries=[]\n",
        "    contents=[]\n",
        "    urls=[]\n",
        "    for article in articles:\n",
        "        text = article[\"content\"]\n",
        "        if text:\n",
        "            summary = text_summarizer(text, num_sentences)\n",
        "            summaries.append(summary)\n",
        "            titles.append(article[\"title\"])\n",
        "            contents.append(extract_content_from_url(article[\"url\"]))  # Extract content from URL\n",
        "            urls.append(article[\"url\"])\n",
        "    return summaries,titles,contents,urls\n",
        "\n",
        "# Example usage\n",
        "query = input(\"Enter a topic to search for news articles: \")\n",
        "num_sentences = int(input(\"Enter the number of sentences for each summary: \"))\n",
        "summaries, titles,contents,urls= fetch_and_summarize_news(query, num_sentences)\n",
        "for i in range(len(titles)):\n",
        "    print(f\"\"\"\\nTitle ->{titles[i]}:\\n\n",
        "            \\nURL ->{urls[i]}\\n\n",
        "            \\nContent ->{contents[i]}\\n\n",
        "            \\nSummaries ->{summaries[i]}\\n\\n\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\vs code\\text-summarizer\\myproject\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "d:\\vs code\\text-summarizer\\myproject\\lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hiten\\.cache\\huggingface\\hub\\models--sshleifer--distilbart-cnn-12-6. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[141], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m summary\n\u001b[0;32m      8\u001b[0m text\u001b[39m=\u001b[39m\u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEnter: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[39mprint\u001b[39m(transformer_summarizer(text))\n",
            "Cell \u001b[1;32mIn[141], line 4\u001b[0m, in \u001b[0;36mtransformer_summarizer\u001b[1;34m(text, num_sentences)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransformer_summarizer\u001b[39m(text, num_sentences\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     summarization_pipeline \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39;49m\u001b[39msummarization\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      5\u001b[0m     summary \u001b[39m=\u001b[39m summarization_pipeline(text, max_length\u001b[39m=\u001b[39m\u001b[39m150\u001b[39m, min_length\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m, do_sample\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, num_beams\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, length_penalty\u001b[39m=\u001b[39m\u001b[39m2.0\u001b[39m)[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39msummary_text\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m summary\n",
            "File \u001b[1;32md:\\vs code\\text-summarizer\\myproject\\lib\\site-packages\\transformers\\pipelines\\__init__.py:905\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m framework \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    904\u001b[0m     model_classes \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[1;32m--> 905\u001b[0m     framework, model \u001b[39m=\u001b[39m infer_framework_load_model(\n\u001b[0;32m    906\u001b[0m         model,\n\u001b[0;32m    907\u001b[0m         model_classes\u001b[39m=\u001b[39mmodel_classes,\n\u001b[0;32m    908\u001b[0m         config\u001b[39m=\u001b[39mconfig,\n\u001b[0;32m    909\u001b[0m         framework\u001b[39m=\u001b[39mframework,\n\u001b[0;32m    910\u001b[0m         task\u001b[39m=\u001b[39mtask,\n\u001b[0;32m    911\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhub_kwargs,\n\u001b[0;32m    912\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[0;32m    913\u001b[0m     )\n\u001b[0;32m    915\u001b[0m model_config \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\n\u001b[0;32m    916\u001b[0m hub_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39m_commit_hash\n",
            "File \u001b[1;32md:\\vs code\\text-summarizer\\myproject\\lib\\site-packages\\transformers\\pipelines\\base.py:230\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39mSelect framework (TensorFlow or PyTorch) to use from the `model` passed. Returns a tuple (framework, model).\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[39m    `Tuple`: A tuple framework, model.\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_tf_available() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_available():\n\u001b[1;32m--> 230\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    231\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAt least one of TensorFlow 2.0 or PyTorch should be installed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTo install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTo install PyTorch, read the instructions at https://pytorch.org/.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    234\u001b[0m     )\n\u001b[0;32m    235\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    236\u001b[0m     model_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_from_pipeline\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m task\n",
            "\u001b[1;31mRuntimeError\u001b[0m: At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/."
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "def transformer_summarizer(text, num_sentences=3):\n",
        "    summarization_pipeline = pipeline(\"summarization\")\n",
        "    summary = summarization_pipeline(text, max_length=150, min_length=30, do_sample=False, num_beams=4, length_penalty=2.0)[0]['summary_text']\n",
        "    return summary\n",
        "\n",
        "text=input(\"Enter: \")\n",
        "print(transformer_summarizer(text))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myproject",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "0596493d71c1d7e07670ead54cd53b4f824399dceff9eb021a9645f9e98e0566"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
